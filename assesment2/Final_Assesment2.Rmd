---
title: "Second Assignment"
author: "Malgorzata, Kevin, Johannes"
date: "09th of February, 2019"
output: 
  pdf_document:
    latex_engine: xelatex
fontsize: 11pt
---

## Microeconometrics 2018/2019 
# Assignment 2

### Group Members: 

- Johannes Wagner  
Humboldt-Universität Berlin - ID 598797 - Msc Statistics  
<wagnejoh@hu-berlin.de>

- Malgorzata Paulina Olesiewicz  
Humboldt-Universität Berlin - ID 598939 - Msc Statistics  
<malgorzata.paulina.olesiewicz@student.hu-berlin.de>

- Kevin Hoppe  
Humboldt-Universität Berlin - ID 598247 -  Msc Statistics  
<Kevin.Hoppe1@web.de>  



## Approximate individual contributions: 

```{r, echo = FALSE}
suppressWarnings(library("kableExtra"))
e=c("1",
    "2",
    "3",
    "4") 
   
f=c("1/3 theory + programming",
    "1/3 theory",
    "1/3 theory",
    "1/3 theory") 
g= c("1/3 theory", 
     "1/3 theory",
     "1/3 theory + programming",
     "1/3 theory") 
 
h= c("1/3 theory", 
     "1/3 theory",
     "1/3 theory",
      "1/3 theory+ programming")
work = data.frame(e,f,g,h)
colnames(work)= c("Task","Johannes","Malgorzata","Kevin")
kable(work)%>% kable_styling() 
```


$$
\pagebreak
$$


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
### Setting up the enviroment
library(foreign, quietly = TRUE)
library(tidyverse, quietly = TRUE)
library(margins, quietly = TRUE)
library(mfx, quietly = TRUE)
#install.packages("caret")
library(caret,quietly = TRUE)
# install.packages("InformationValue")
library(InformationValue, quietly = TRUE)
library(xtable, quietly = TRUE)
#install.packages("olsrr")
library(olsrr, quietly = TRUE)
#install.packages("nnet")
library(nnet, quietly = TRUE)
library(dplyr, quietly = TRUE)
#install.packages("mlogit")
library(mlogit, quietly = TRUE)
library(kableExtra, quietly = TRUE)
```

```{r, include = FALSE}
# clear environment
rm(list = ls())
# Define Directory
#dir <- "~/R/git/Micro_Ass1"
dir <- "C:/Users/Nutzer/Desktop"
setwd(dir)
### loading the data and looking up meaning of the variables
data <- read.dta("loanapp1.dta")
(variables=cbind(colnames(data),attr(data, "var.labels")))
# Model Selection ---------------------------------------------------------
# For simplicity reasons we can use a simple OLS model for the selection process
# remove variables which are directly related to rejection and have no explanatory power given our social theory: unver
# remove missings for the purpose of model selection
data_woNA <- data[complete.cases(data),] %>% dplyr::select(-c(approve, action, unver))
# regress the depend variable on all regressors
fit <- lm(reject~.,data=data_woNA)
## Perform forward stepwise selection to find most important variables
ols_step_forward_p(fit, details = FALSE, penter = 0.001)
## Select the four significant variables which can be explained trough our theory:
# inson, pubrec, white, obrat

## Calculate logit model with MPEs at means
dataSelect <- dplyr::select(data, c(reject, sch, married, netw, inson, pubrec, white, obrat))
dataSelect <- dataSelect[complete.cases(dataSelect),] 
logit_MPresults <- logitmfx(reject~sch + married + netw + inson + pubrec + white + obrat, data = dataSelect, atmean=TRUE)
# Logit Model
model=glm(reject~sch + married + netw + inson + pubrec + white + obrat, data =dataSelect, family = "binomial"(link="logit"))


## Calculate the probability for the average individual in our sample:
# Vector of Means
mean<-c(mean(dataSelect$sch),mean(dataSelect$married),mean(dataSelect$netw),mean(dataSelect$inson),mean(dataSelect$pubrec),mean(dataSelect$white),mean(dataSelect$obrat))
dim(mean)<-c(1,7)
names(mean)<-c("sch","married","netw","inson","pubrec","white","obrat");mean
# add Intercept
mean<-cbind(1,mean)
# Calculate P(Y=1|X) for Mean values in the sample
Prob1=1/(1+exp(-(model$coefficients%*%t(mean))))
```


## Task 1: Choosing the variables

The choice of variables should be grounded on both theory and empirical evidence. Our theoretical perspective is guided by the assumption that higher social, cultural and economical capital leads to a lower probability of rejection. First, we chose three variables representing relevant social characteristics given above theory that are stored in the variables "education", "marital status", and "wealth". We then used forward stepwise selection to identify those covariates with the highest empirical relevance for the dependent variable "rejection". From the resulting list of nine empirically highly relevant variables, we picked four that are also theoretically relevant, thus obtaining a total of seven regressors. 

To create the logit model (table 1) we have chosen following variables with regard to our theory: 

```{r , echo=FALSE}
a=c("Education (cultural capital)",
    "Marital Status (social capital)",
    "Wealth in Dollar (economic capital)",
    "Private mortgage insurance (economic capital)", 
    "Former bankruptcy (economic capital)",
    "Ethnic majority (social & cultural capital)",
    "Ratio of obligations to income (economic capital)") 
   
b=c("sch",
    "married",
    "netw",
    "inson",
    "pubrec",
    "white",
    "obrat") 
c= c("[0,1]", 
     "[0,1]",
     "[-7919, 28023]",
     "[0,1]",
     "[0,1]",
     "[0,1]",
     "[0, 95]") 
 
d= c("-", 
     "-",
     "-",
     "-",
     "+",
     "-",
     "+") 
vars = data.frame(a,b,c,d)
colnames(vars)= c("Indicator","Variable","Scale", "Expected effect")
kable(vars)%>% kable_styling()
```

Given our seven explanatory variables, we can now estimate the conditional probability of a rejection. In our sample, the estimated probability of rejection for an individual with average characteristics is $\mathrm { P } \left( Y = 1 | X = \overline { \mathbf { x } } \right) = 9.04 \%$.

##Task 2: Results interpretation

Just looking at our estimated coefficients we can not say which one has the biggest effect on our dependent variable. That is because we can not directly compare the magnitude of coefficients from explanatory variables with different scales. For interpretation, we usually want to use coefficients as marginal probability effects given a little change in the explanatory variable. Since the effect of a "unit change" can mean quite different effects given the scale of the variable, you cannot compare variables with different scales. For example, given our variables, a unit change in the binary variable "pubrec" represents the difference between just two options (Yes/No) while a unit change in "obrat" just represents one step on a scale of many options. Furthermore, coefficients are random variables and have to be tested for them being significantly different from zero and from each other. Also, before making any interpretations, the coefficients should be transformed into marginal probability effects.  


```{r , echo=FALSE}
## Print the Logit Model and the estimated probabilities with MPE at means
fm1.table <- xtable(model)
kable(fm1.table, caption = "Logit Model")%>% kable_styling()

#fm2.table <- xtable(logit_MPresults[1])
# kable(logit_MPresults[1], caption = "Logit Model with MPE at means")%>% kable_styling()
```

##Task 3: Sensitivity and Specificity

The notion of sensitivity and specificity is used to describe how accurately a model predicts the binary outcomes. Sensitivity is the fraction of correctly predicted positive $(Y=1)$ outcomes and specificity describes the fraction of correctly predicted negative $(Y=0)$ outcomes. We aim to find an optimal equilibrium between the two fractions, which allows us the best possible simultaneous prediction of both outcomes.    

In our prediction, we use $c$ as a threshold above which the outcome is predicted to be positive. Consequently, any result of our logit model which will be equal or below the threshold will be precited to be negative. 

The most logical starting point for the binary response prediction model is $c = 0.5$

```{r, echo=FALSE}

predicted=predict(model,dataSelect, type="response")
sen_1=sensitivity(dataSelect$reject,predicted,threshold = 0.5)
spec_1=specificity(dataSelect$reject,predicted,threshold = 0.5)
vars_1 = data.frame("0.5",sen_1, spec_1)
colnames(vars_1)= c("Threshold","Sensitivity","Specificity")
kable(vars_1)%>% kable_styling()
```


For $c = 0.5$, we observe that almost all (99%) negative responses but only 24% of the positive responses are predicted correctly. Since a threshold $c$ that is closer to 1 results in a higher specificity (the likelihood that we will predict negative responses increases) we will decrease the threshold to $c = 0.3$. 


```{r, echo=FALSE}
sen_2=sensitivity(dataSelect$reject,predicted,threshold = 0.3)
spec_2=specificity(dataSelect$reject,predicted,threshold = 0.3)
vars_2 = data.frame("0.3",sen_2, spec_2)
colnames(vars_2)= c("Threshold","Sensitivity","Specificity")
kable(vars_2)%>% kable_styling()
```
We observe some improvement in the accuracy of predicted positives (sensitivity now at 36%) while keeping the  specificity at a high level (now 96%). We are going in the right direction. To find the optimal prediction threshold $c$ we used the "InformationValue" package.

```{r, echo=FALSE}
cut= optimalCutoff(actuals = dataSelect$reject, predictedScores =predicted,optimiseFor="Both")
sen_3=sensitivity(dataSelect$reject,predicted,threshold =cut)
spec_3=specificity(dataSelect$reject,predicted,threshold =cut)
vars_3 = data.frame(cut,sen_3, spec_3 )
colnames(vars_3)= c("Optimal Cut off","Sensitivity","Specificity")
kable(vars_3)%>% kable_styling()
```

The optimal cut-off level is $c=0.118$ where 65% of positive outcomes and 83% of negative outcomes are predicted correctly.

### Taks4:  Multinomial Logit



```{r, include=FALSE}
## Load data and extract the 7 variables that we chose 
## as a group:
##
## 1. Education (sch): [0,1]
## 2. marital status (married): [0,1]
## 3. Existence of private mortgage insurance (inson): [0,1]
## 4. Net worth (netw): [-7919, 28023]
## 5. Former bankruptcy (pubrec): [0,1]
## 6. Ethnic majority (white): [0,1]
## 7. Ratio of income and liabilities (obrat) : [0-95]
dat.red <- dplyr::select(data, reject, sch, married, inson, cons, pubrec, white, obrat, netw); as.tibble(dat.red)
## Coding categorial variables as dummy variables:
dummy.var <- function(var){
  
  if(min(unique(var), na.rm = T) == 0){
    var <- var + 1
  }
  
  len.var <- length(var)
  levels.var <- var %>% as.factor %>% levels %>% length
  levels.dummy <- levels.var - 1
  
  dummy <- matrix(NA,
                  nrow = len.var,
                  ncol = levels.dummy)
  for(j in 1:levels.var){
    
    match.loc <- which(var == unique(var)[j])
    
    for(i in match.loc){
      
      dummy.vec <- rep(0, levels.dummy)
      dummy.vec[unique(var)[j] - 1] <- 1
      dummy[i,] <- dummy.vec
    }
  }
  return(dummy)
}
sch <- dummy.var(dat.red$sch); head(sch)
married <- dummy.var(dat.red$married); head(married)
inson <- dummy.var(dat.red$inson); head(inson)
#cons <- dummy.var(dat.red$cons); head(cons)
pubrec <- dummy.var(dat.red$pubrec); head(pubrec)
white <- dummy.var(dat.red$white); head(white)
## Put together data set for regression models:
dat <- data.frame("reject" = dat.red$reject,
                  "educ" = sch,
                  "marry" = married,
                  "insur" = inson,
                  "netw" = dat.red$netw,
                  "bankr" = pubrec,
                  "white" = white,
                  "oblig" = dat.red$obrat)
dat.mnl <- mlogit.data(dat, shape = "wide", choice = "reject")
## Formulas for regression models:
form <- 'reject ~ educ + marry + insur + netw + bankr + white + oblig'
form.mnl <- mFormula(appr ~ educ + marry + insur + netw + bankr + white + oblig)
## Estimate a binomial logit model:
head(dat); binom <- glm(formula = form, data = dat, family = "binomial"(link = "logit"))
summary(binom)
## Estimate a multinomial logit model:
head(dat.mnl); multinom <- multinom(formula = form, data = dat)
summary(multinom)
## Comparison of coefficient estimates:
beta.diff <- cbind(coef(binom) - coef(multinom)); beta.diff
```


The difference in the coefficient estimates is zero up to at least the fourth 
decimal place:

```{r, echo = FALSE, include = TRUE}
kable(beta.diff, digit=6 ) %>% kable_styling(position = "center") 
```


This is because the multinomial logit model (MNL) reduces to the 
binomial logit model in case of a binomial dependent variable as can be seen in the formulas. In the MNL, the probability $\pi_{ij}$ of individual $i$ choosing alternative $j$ is given by:

  $$ \pi_{ij_{multinomial}} = \frac{\exp(x_{i}'\beta_{j})}{\sum_{r=1}^J \exp{x_{i}'\beta_{j}}}. $$

Compare this to the binomial logit model, where the probability $\pi_{i}$ of individual $i$ 
picking alternative $j = 1$ is given by:

  $$ \pi_{i_{binomial}} = \frac{\exp(x_{i}'\beta)}{1 + \exp(x_{i}'\beta)}.  $$
  
In the MNL, due to identification constraints, $\beta_{1}$ is fixed at $0$. This establishes $j = 1$ as the reference category. For the remaining $J-1$ categories, $\beta_{j}$ coefficients are estimated. If the dependent variable has only two categories, i.e. $J = 2$, this means that only one $\beta$ and one $\pi_{i}$ need to be calculated (for the one category that is not the reference category) so the index $j$ in $\pi_{ij}$ and $\beta_{j}$ can be dropped. Since the constraint for $\beta_{1} = 0$ means that $\exp{(x_{i}'\beta_{1})}$ evaluates to $1$, this reduces the denominator in the MNL to $1 + \exp(x_{i}'\beta_{2})$. After dropping the now obsolete index of the coefficient vector, the two formulas given above are equal.
